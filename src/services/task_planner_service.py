"""
ã‚¿ã‚¹ã‚¯è¨ˆç”»ã‚µãƒ¼ãƒ“ã‚¹
å¤§ã‚¿ã‚¹ã‚¯ã‚’å°ã‚¿ã‚¹ã‚¯ã«åˆ†è§£ã—ã€å€‹åˆ¥æœ€é©åŒ–ã•ã‚ŒãŸå®Ÿè¡Œè¨ˆç”»ã‚’ç”Ÿæˆ
"""

import json
import logging
import uuid
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict


def safe_json_dumps(obj, **kwargs):
    """datetimeå¯¾å¿œã®JSONã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¶ãƒ¼"""
    def default_serializer(o):
        if isinstance(o, datetime):
            return o.isoformat()
        raise TypeError(f"Object of type {type(o)} is not JSON serializable")
    
    return json.dumps(obj, default=default_serializer, **kwargs)

from .llm_service import LLMService
from ..models import Employee


@dataclass
class SubTask:
    """ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã®å®šç¾©"""
    id: str
    name: str
    description: str
    priority: str  # critical, high, medium, low
    complexity: str  # simple, moderate, complex
    estimated_duration: int  # åˆ†
    dependencies: List[str]  # ä¾å­˜ã™ã‚‹ã‚¿ã‚¹ã‚¯ã®ID
    required_skills: List[str]
    success_criteria: List[str]
    resources_needed: List[str]
    potential_obstacles: List[str]
    mitigation_strategies: List[str]
    created_at: datetime
    due_date: Optional[datetime] = None
    status: str = "pending"  # pending, in_progress, completed, blocked, failed


@dataclass
class LearningMilestone:
    """å­¦ç¿’ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ã®å®šç¾©"""
    id: str
    name: str
    description: str
    target_date: datetime
    success_metrics: List[str]
    validation_methods: List[str]
    reward_system: str
    dependencies: List[str]


@dataclass
class AdaptiveStrategy:
    """é©å¿œæˆ¦ç•¥ã®å®šç¾©"""
    strategy_type: str  # learning_pace, difficulty, motivation
    trigger_conditions: List[str]
    adaptations: List[str]
    monitoring_metrics: List[str]
    escalation_criteria: List[str]


class TaskPlannerService:
    """
    LLMã‚’æ´»ç”¨ã—ã¦ã‚¿ã‚¹ã‚¯ã®åˆ†è§£ã¨è¨ˆç”»ã‚’è¡Œã†
    å€‹äººã«æœ€é©åŒ–ã•ã‚ŒãŸå­¦ç¿’æˆ¦ç•¥ã‚’ç”Ÿæˆ
    """
    
    def __init__(self):
        self.llm_service = LLMService()
        self.logger = logging.getLogger(__name__)
        self.planning_history: List[Dict[str, Any]] = []
        
    async def create_personalized_growth_strategy(self, employee: Employee, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """å€‹åˆ¥æœ€é©åŒ–æˆé•·æˆ¦ç•¥ã®ä½œæˆ"""
        self.logger.info(f"ğŸ“‹ {employee.name}ã•ã‚“ã®å€‹åˆ¥æˆé•·æˆ¦ç•¥ã‚’ä½œæˆä¸­...")
        
        # LLMã«ã‚ˆã‚‹æˆ¦ç•¥è¨­è¨ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        strategy_prompt = self._create_strategy_prompt(employee, analysis)
        
        # åŸºæœ¬æˆ¦ç•¥ã®ç”Ÿæˆ
        base_strategy = await self.llm_service.generate_growth_strategy(strategy_prompt)
        
        # ã‚¿ã‚¹ã‚¯åˆ†è§£ã®å®Ÿè¡Œ
        decomposed_tasks = await self._decompose_growth_tasks(employee, base_strategy, analysis)
        
        # ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ã®è¨­å®š
        milestones = await self._generate_adaptive_milestones(employee, decomposed_tasks, analysis)
        
        # é©å¿œæˆ¦ç•¥ã®é–‹ç™º
        adaptive_strategies = await self._develop_adaptive_strategies(employee, analysis)
        
        # ãƒªã‚¹ã‚¯è©•ä¾¡ã¨è»½æ¸›ç­–
        risk_assessment = await self._assess_and_mitigate_risks(employee, decomposed_tasks, analysis)
        
        # çµ±åˆã•ã‚ŒãŸæˆé•·æˆ¦ç•¥
        integrated_strategy = {
            "employee_id": employee.id,
            "strategy_id": str(uuid.uuid4()),
            "created_at": datetime.now(),
            "base_strategy": base_strategy,
            "decomposed_tasks": [asdict(task) for task in decomposed_tasks],
            "milestones": [asdict(milestone) for milestone in milestones],
            "adaptive_strategies": [asdict(strategy) for strategy in adaptive_strategies],
            "risk_assessment": risk_assessment,
            "estimated_completion": self._calculate_completion_date(decomposed_tasks),
            "success_probability": await self._calculate_success_probability(employee, decomposed_tasks, analysis)
        }
        
        # è¨ˆç”»å±¥æ­´ã«è¨˜éŒ²
        self.planning_history.append(integrated_strategy)
        
        return integrated_strategy
    
    async def _decompose_growth_tasks(self, employee: Employee, base_strategy: Dict[str, Any], analysis: Dict[str, Any]) -> List[SubTask]:
        """æˆé•·ã‚¿ã‚¹ã‚¯ã®è©³ç´°åˆ†è§£"""
        self.logger.info("ğŸ”„ æˆé•·ã‚¿ã‚¹ã‚¯ã‚’è©³ç´°åˆ†è§£ä¸­...")
        
        decomposition_prompt = f"""
        {employee.name}ã•ã‚“ã®æˆé•·æˆ¦ç•¥ã‚’å®Ÿè¡Œå¯èƒ½ãªå°ã‚¿ã‚¹ã‚¯ã«åˆ†è§£ã—ã¦ãã ã•ã„ã€‚
        
        åŸºæœ¬æˆ¦ç•¥: {safe_json_dumps(base_strategy, ensure_ascii=False, indent=2)}
        åˆ†æçµæœ: {safe_json_dumps(analysis, ensure_ascii=False, indent=2)}
        
        ç¤¾å“¡ã®ç‰¹æ€§:
        - å­¦ç¿’ãƒšãƒ¼ã‚¹: {employee.learning_pace}
        - å¼·ã¿: {', '.join(employee.strengths)}
        - æ”¹å–„é ˜åŸŸ: {', '.join(employee.improvement_areas)}
        - å®Œäº†ç ”ä¿®: {', '.join(employee.completed_trainings)}
        
        ä»¥ä¸‹ã®æ¡ä»¶ã§å°ã‚¿ã‚¹ã‚¯ã«åˆ†è§£ã—ã¦ãã ã•ã„ï¼š
        - å„ã‚¿ã‚¹ã‚¯ã¯1-3æ—¥ã§å®Œäº†å¯èƒ½
        - å…·ä½“çš„ã§æ¸¬å®šå¯èƒ½ãªæˆåŠŸåŸºæº–
        - ä¾å­˜é–¢ä¿‚ã‚’æ˜ç¢ºåŒ–
        - å­¦ç¿’ãƒšãƒ¼ã‚¹ã«é©ã—ãŸé›£æ˜“åº¦èª¿æ•´
        - æ½œåœ¨çš„ãªéšœå®³ã¨å¯¾ç­–ã‚’å«ã‚€
        
        JSONé…åˆ—å½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ï¼š
        [
            {{
                "name": "ã‚¿ã‚¹ã‚¯å",
                "description": "è©³ç´°èª¬æ˜",
                "priority": "critical/high/medium/low",
                "complexity": "simple/moderate/complex",
                "estimated_duration": åˆ†æ•°,
                "dependencies": ["ä¾å­˜ã‚¿ã‚¹ã‚¯å"],
                "required_skills": ["å¿…è¦ã‚¹ã‚­ãƒ«"],
                "success_criteria": ["æˆåŠŸåŸºæº–"],
                "resources_needed": ["å¿…è¦ãƒªã‚½ãƒ¼ã‚¹"],
                "potential_obstacles": ["æ½œåœ¨çš„éšœå®³"],
                "mitigation_strategies": ["è»½æ¸›ç­–"]
            }}
        ]
        """
        
        try:
            decomposed_data = await self.llm_service.decompose_tasks(decomposition_prompt)
            
            if isinstance(decomposed_data, str):
                decomposed_data = json.loads(decomposed_data)
            
            subtasks = []
            for i, task_data in enumerate(decomposed_data):
                subtask = SubTask(
                    id=f"task_{employee.id}_{i+1}_{int(datetime.now().timestamp())}",
                    name=task_data.get("name", f"ã‚¿ã‚¹ã‚¯ {i+1}"),
                    description=task_data.get("description", ""),
                    priority=task_data.get("priority", "medium"),
                    complexity=task_data.get("complexity", "moderate"),
                    estimated_duration=task_data.get("estimated_duration", 60),
                    dependencies=task_data.get("dependencies", []),
                    required_skills=task_data.get("required_skills", []),
                    success_criteria=task_data.get("success_criteria", []),
                    resources_needed=task_data.get("resources_needed", []),
                    potential_obstacles=task_data.get("potential_obstacles", []),
                    mitigation_strategies=task_data.get("mitigation_strategies", []),
                    created_at=datetime.now()
                )
                subtasks.append(subtask)
            
            # ã‚¿ã‚¹ã‚¯ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã®æœ€é©åŒ–
            optimized_tasks = await self._optimize_task_scheduling(subtasks, employee)
            
            return optimized_tasks
            
        except Exception as e:
            self.logger.error(f"ã‚¿ã‚¹ã‚¯åˆ†è§£ã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬çš„ãªã‚¿ã‚¹ã‚¯åˆ†è§£
            return self._create_fallback_tasks(employee, analysis)
    
    async def _generate_adaptive_milestones(self, employee: Employee, tasks: List[SubTask], analysis: Dict[str, Any]) -> List[LearningMilestone]:
        """é©å¿œçš„ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ã®ç”Ÿæˆ"""
        self.logger.info("ğŸ¯ é©å¿œçš„ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ã‚’ç”Ÿæˆä¸­...")
        
        milestone_prompt = f"""
        {employee.name}ã•ã‚“ã®å­¦ç¿’ã‚¿ã‚¹ã‚¯ã«åŸºã¥ã„ã¦ã€é©å¿œçš„ãªãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ã‚’è¨­è¨ˆã—ã¦ãã ã•ã„ã€‚
        
        ã‚¿ã‚¹ã‚¯æƒ…å ±: {safe_json_dumps([asdict(task) for task in tasks], ensure_ascii=False, indent=2)}
        å­¦ç¿’ãƒšãƒ¼ã‚¹: {employee.learning_pace}
        
        ä»¥ä¸‹ã®åŸºæº–ã§ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ã‚’è¨­è¨ˆï¼š
        - å­¦ç¿’ãƒšãƒ¼ã‚¹ã«å¿œã˜ãŸé–“éš”èª¿æ•´
        - å…·ä½“çš„ã§æ¸¬å®šå¯èƒ½ãªæˆåŠŸæŒ‡æ¨™
        - ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ç¶­æŒã®ãŸã‚ã®å ±é…¬ã‚·ã‚¹ãƒ†ãƒ 
        - æ®µéšçš„é›£æ˜“åº¦ä¸Šæ˜‡
        - ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ã®çµ„ã¿è¾¼ã¿
        
        JSONé…åˆ—ã§è¿”ã—ã¦ãã ã•ã„ï¼š
        [
            {{
                "name": "ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³å",
                "description": "è©³ç´°èª¬æ˜",
                "target_date": "YYYY-MM-DD",
                "success_metrics": ["æˆåŠŸæŒ‡æ¨™"],
                "validation_methods": ["æ¤œè¨¼æ–¹æ³•"],
                "reward_system": "å ±é…¬ã‚·ã‚¹ãƒ†ãƒ ",
                "dependencies": ["ä¾å­˜ã‚¿ã‚¹ã‚¯ID"]
            }}
        ]
        """
        
        try:
            milestone_data = await self.llm_service.generate_milestones(milestone_prompt)
            
            if isinstance(milestone_data, str):
                milestone_data = json.loads(milestone_data)
            
            milestones = []
            for i, data in enumerate(milestone_data):
                milestone = LearningMilestone(
                    id=f"milestone_{employee.id}_{i+1}_{int(datetime.now().timestamp())}",
                    name=data.get("name", f"ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ {i+1}"),
                    description=data.get("description", ""),
                    target_date=datetime.strptime(data.get("target_date", (datetime.now() + timedelta(weeks=i+1)).strftime("%Y-%m-%d")), "%Y-%m-%d"),
                    success_metrics=data.get("success_metrics", []),
                    validation_methods=data.get("validation_methods", []),
                    reward_system=data.get("reward_system", "åŸºæœ¬çš„ãªé”æˆèªè­˜"),
                    dependencies=data.get("dependencies", [])
                )
                milestones.append(milestone)
            
            return milestones
            
        except Exception as e:
            self.logger.error(f"ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return self._create_fallback_milestones(employee, tasks)
    
    async def _develop_adaptive_strategies(self, employee: Employee, analysis: Dict[str, Any]) -> List[AdaptiveStrategy]:
        """é©å¿œæˆ¦ç•¥ã®é–‹ç™º"""
        self.logger.info("ğŸ›ï¸ é©å¿œæˆ¦ç•¥ã‚’é–‹ç™ºä¸­...")
        
        strategy_prompt = f"""
        {employee.name}ã•ã‚“ã®ç‰¹æ€§ã«åŸºã¥ã„ã¦ã€å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹ä¸­ã®é©å¿œæˆ¦ç•¥ã‚’è¨­è¨ˆã—ã¦ãã ã•ã„ã€‚
        
        ç¤¾å“¡ç‰¹æ€§:
        - å­¦ç¿’ãƒšãƒ¼ã‚¹: {employee.learning_pace}
        - å¼·ã¿: {', '.join(employee.strengths)}
        - æ”¹å–„é ˜åŸŸ: {', '.join(employee.improvement_areas)}
        
        åˆ†æçµæœ: {safe_json_dumps(analysis, ensure_ascii=False, indent=2)}
        
        ä»¥ä¸‹ã®æˆ¦ç•¥ã‚¿ã‚¤ãƒ—ã‚’è¨­è¨ˆï¼š
        1. learning_pace: å­¦ç¿’ãƒšãƒ¼ã‚¹èª¿æ•´æˆ¦ç•¥
        2. difficulty: é›£æ˜“åº¦é©å¿œæˆ¦ç•¥
        3. motivation: ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ç¶­æŒæˆ¦ç•¥
        4. engagement: ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆå‘ä¸Šæˆ¦ç•¥
        5. support: ã‚µãƒãƒ¼ãƒˆå¼·åŒ–æˆ¦ç•¥
        
        å„æˆ¦ç•¥ã«ã¤ã„ã¦ä»¥ä¸‹ã‚’å®šç¾©ï¼š
        - ãƒˆãƒªã‚¬ãƒ¼æ¡ä»¶ï¼ˆã©ã‚“ãªçŠ¶æ³ã§ç™ºå‹•ã™ã‚‹ã‹ï¼‰
        - å…·ä½“çš„ãªé©å¿œå†…å®¹
        - ç›£è¦–ã™ã¹ãæŒ‡æ¨™
        - ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åŸºæº–
        
        JSONé…åˆ—ã§è¿”ã—ã¦ãã ã•ã„ï¼š
        [
            {{
                "strategy_type": "æˆ¦ç•¥ã‚¿ã‚¤ãƒ—",
                "trigger_conditions": ["ãƒˆãƒªã‚¬ãƒ¼æ¡ä»¶"],
                "adaptations": ["é©å¿œå†…å®¹"],
                "monitoring_metrics": ["ç›£è¦–æŒ‡æ¨™"],
                "escalation_criteria": ["ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åŸºæº–"]
            }}
        ]
        """
        
        try:
            strategy_data = await self.llm_service.develop_adaptive_strategies(strategy_prompt)
            
            if isinstance(strategy_data, str):
                strategy_data = json.loads(strategy_data)
            
            strategies = []
            for data in strategy_data:
                strategy = AdaptiveStrategy(
                    strategy_type=data.get("strategy_type", "general"),
                    trigger_conditions=data.get("trigger_conditions", []),
                    adaptations=data.get("adaptations", []),
                    monitoring_metrics=data.get("monitoring_metrics", []),
                    escalation_criteria=data.get("escalation_criteria", [])
                )
                strategies.append(strategy)
            
            return strategies
            
        except Exception as e:
            self.logger.error(f"é©å¿œæˆ¦ç•¥é–‹ç™ºã‚¨ãƒ©ãƒ¼: {e}")
            return self._create_fallback_adaptive_strategies(employee)
    
    async def _assess_and_mitigate_risks(self, employee: Employee, tasks: List[SubTask], analysis: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒªã‚¹ã‚¯è©•ä¾¡ã¨è»½æ¸›ç­–ã®ç­–å®š"""
        self.logger.info("âš ï¸ ãƒªã‚¹ã‚¯è©•ä¾¡ã¨è»½æ¸›ç­–ã‚’ç­–å®šä¸­...")
        
        risk_prompt = f"""
        {employee.name}ã•ã‚“ã®æˆé•·è¨ˆç”»ã«ãŠã‘ã‚‹ãƒªã‚¹ã‚¯ã‚’è©•ä¾¡ã—ã€è»½æ¸›ç­–ã‚’ç­–å®šã—ã¦ãã ã•ã„ã€‚
        
        è¨ˆç”»ã•ã‚ŒãŸã‚¿ã‚¹ã‚¯: {safe_json_dumps([asdict(task) for task in tasks], ensure_ascii=False, indent=2)}
        åˆ†æçµæœ: {safe_json_dumps(analysis, ensure_ascii=False, indent=2)}
        
        ä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰ãƒªã‚¹ã‚¯è©•ä¾¡ï¼š
        1. å­¦ç¿’ãƒšãƒ¼ã‚¹ã¨ã‚¿ã‚¹ã‚¯é‡ã®ãƒŸã‚¹ãƒãƒƒãƒ
        2. ã‚¹ã‚­ãƒ«ã‚®ãƒ£ãƒƒãƒ—ã«ã‚ˆã‚‹å®Ÿè¡Œå›°é›£
        3. ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ä½ä¸‹ã®å¯èƒ½æ€§
        4. æ™‚é–“ç®¡ç†ã®èª²é¡Œ
        5. å¤–éƒ¨è¦å› ï¼ˆæ¥­å‹™è² è·ç­‰ï¼‰ã®å½±éŸ¿
        6. ãƒªã‚½ãƒ¼ã‚¹ä¸è¶³ã®ãƒªã‚¹ã‚¯
        
        ä»¥ä¸‹ã®å½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ï¼š
        {{
            "identified_risks": [
                {{
                    "risk_type": "ãƒªã‚¹ã‚¯ã‚¿ã‚¤ãƒ—",
                    "description": "ãƒªã‚¹ã‚¯èª¬æ˜",
                    "probability": "ç™ºç”Ÿç¢ºç‡(high/medium/low)",
                    "impact": "å½±éŸ¿åº¦(high/medium/low)",
                    "risk_score": "ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢(1-10)"
                }}
            ],
            "mitigation_strategies": [
                {{
                    "risk_type": "å¯¾è±¡ãƒªã‚¹ã‚¯ã‚¿ã‚¤ãƒ—",
                    "strategy": "è»½æ¸›æˆ¦ç•¥",
                    "preventive_actions": ["äºˆé˜²ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"],
                    "contingency_plans": ["ç·Šæ€¥æ™‚è¨ˆç”»"]
                }}
            ],
            "monitoring_plan": {{
                "early_warning_indicators": ["æ—©æœŸè­¦å‘ŠæŒ‡æ¨™"],
                "monitoring_frequency": "ç›£è¦–é »åº¦",
                "escalation_procedures": ["ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ‰‹é †"]
            }},
            "overall_risk_level": "å…¨ä½“ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«(low/medium/high)"
        }}
        """
        
        try:
            risk_assessment = await self.llm_service.assess_risks(risk_prompt)
            
            if isinstance(risk_assessment, str):
                risk_assessment = json.loads(risk_assessment)
            
            return risk_assessment
            
        except Exception as e:
            self.logger.error(f"ãƒªã‚¹ã‚¯è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
            return self._create_fallback_risk_assessment()
    
    async def _optimize_task_scheduling(self, tasks: List[SubTask], employee: Employee) -> List[SubTask]:
        """ã‚¿ã‚¹ã‚¯ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã®æœ€é©åŒ–"""
        self.logger.info("â° ã‚¿ã‚¹ã‚¯ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã‚’æœ€é©åŒ–ä¸­...")
        
        # å­¦ç¿’ãƒšãƒ¼ã‚¹ã«åŸºã¥ãæ™‚é–“èª¿æ•´
        pace_multiplier = 1.0 / employee.learning_pace if employee.learning_pace > 0 else 1.0
        
        optimized_tasks = []
        current_date = datetime.now()
        
        # ä¾å­˜é–¢ä¿‚ã‚’è€ƒæ…®ã—ãŸã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°
        task_dict = {task.name: task for task in tasks}
        scheduled_tasks = set()
        
        def can_schedule(task: SubTask) -> bool:
            return all(dep in scheduled_tasks for dep in task.dependencies)
        
        while len(scheduled_tasks) < len(tasks):
            schedulable_tasks = [task for task in tasks 
                               if task.name not in scheduled_tasks and can_schedule(task)]
            
            if not schedulable_tasks:
                # å¾ªç’°ä¾å­˜ã®è§£æ±º
                remaining_tasks = [task for task in tasks if task.name not in scheduled_tasks]
                if remaining_tasks:
                    schedulable_tasks = [remaining_tasks[0]]  # æœ€åˆã®ã‚¿ã‚¹ã‚¯ã‚’å¼·åˆ¶ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
            
            for task in schedulable_tasks:
                # æ™‚é–“èª¿æ•´
                adjusted_duration = int(task.estimated_duration * pace_multiplier)
                task.estimated_duration = adjusted_duration
                
                # æœŸé™è¨­å®š
                task.due_date = current_date + timedelta(minutes=adjusted_duration)
                current_date = task.due_date
                
                optimized_tasks.append(task)
                scheduled_tasks.add(task.name)
                
                break  # ä¸€ã¤ãšã¤å‡¦ç†
        
        return optimized_tasks
    
    def _calculate_completion_date(self, tasks: List[SubTask]) -> datetime:
        """å®Œäº†äºˆå®šæ—¥ã®è¨ˆç®—"""
        if not tasks:
            return datetime.now() + timedelta(days=30)
        
        latest_due_date = max(task.due_date for task in tasks if task.due_date)
        return latest_due_date if latest_due_date else datetime.now() + timedelta(days=30)
    
    async def _calculate_success_probability(self, employee: Employee, tasks: List[SubTask], analysis: Dict[str, Any]) -> float:
        """æˆåŠŸç¢ºç‡ã®è¨ˆç®—"""
        try:
            # åŸºæœ¬ç¢ºç‡ï¼ˆå­¦ç¿’ãƒšãƒ¼ã‚¹ãƒ™ãƒ¼ã‚¹ï¼‰
            base_probability = min(0.9, employee.learning_pace * 0.7)
            
            # ã‚¿ã‚¹ã‚¯è¤‡é›‘åº¦ã«ã‚ˆã‚‹èª¿æ•´
            complexity_penalty = 0
            for task in tasks:
                if task.complexity == "complex":
                    complexity_penalty += 0.1
                elif task.complexity == "moderate":
                    complexity_penalty += 0.05
            
            # ãƒªã‚¹ã‚¯è¦å› ã«ã‚ˆã‚‹èª¿æ•´
            risk_factors = analysis.get("risk_factors", [])
            risk_penalty = len(risk_factors) * 0.05
            
            # æœ€çµ‚ç¢ºç‡è¨ˆç®—
            final_probability = max(0.1, base_probability - complexity_penalty - risk_penalty)
            
            return round(final_probability, 2)
            
        except Exception:
            return 0.7  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    
    def _create_strategy_prompt(self, employee: Employee, analysis: Dict[str, Any]) -> str:
        """æˆ¦ç•¥ç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½œæˆ"""
        return f"""
        {employee.name}ã•ã‚“ã®å€‹åˆ¥æœ€é©åŒ–æˆé•·æˆ¦ç•¥ã‚’è¨­è¨ˆã—ã¦ãã ã•ã„ã€‚
        
        ç¤¾å“¡åŸºæœ¬æƒ…å ±:
        - åå‰: {employee.name}
        - éƒ¨ç½²: {employee.department.value}
        - å­¦ç¿’ãƒšãƒ¼ã‚¹: {employee.learning_pace}
        - å¼·ã¿: {', '.join(employee.strengths)}
        - æ”¹å–„é ˜åŸŸ: {', '.join(employee.improvement_areas)}
        - å®Œäº†ç ”ä¿®: {', '.join(employee.completed_trainings)}
        - ç¾åœ¨ã®ç›®æ¨™: {', '.join(employee.current_objectives)}
        
        åˆ†æçµæœ: {safe_json_dumps(analysis, ensure_ascii=False, indent=2)}
        
        ä»¥ä¸‹ã®è¦ç´ ã‚’å«ã‚€åŒ…æ‹¬çš„æˆ¦ç•¥ã‚’è¨­è¨ˆï¼š
        1. å€‹åˆ¥åŒ–å­¦ç¿’ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
        2. ã‚¹ã‚­ãƒ«é–‹ç™ºãƒ—ãƒ©ã‚¤ã‚ªãƒªãƒ†ã‚£
        3. æ®µéšçš„æˆé•·ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—
        4. ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ç¶­æŒæˆ¦ç•¥
        5. é€²æ—æ¸¬å®šæ–¹æ³•
        6. ã‚µãƒãƒ¼ãƒˆä½“åˆ¶
        
        JSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ï¼š
        {{
            "strategic_approach": "æˆ¦ç•¥çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ",
            "learning_methodology": "å­¦ç¿’æ–¹æ³•è«–",
            "skill_priorities": ["ã‚¹ã‚­ãƒ«å„ªå…ˆé †ä½"],
            "growth_phases": [
                {{
                    "phase": "ãƒ•ã‚§ãƒ¼ã‚ºå",
                    "duration": "æœŸé–“",
                    "objectives": ["ç›®æ¨™"],
                    "key_activities": ["ä¸»è¦æ´»å‹•"]
                }}
            ],
            "motivation_strategy": "ãƒ¢ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³æˆ¦ç•¥",
            "progress_metrics": ["é€²æ—æŒ‡æ¨™"],
            "support_requirements": ["ã‚µãƒãƒ¼ãƒˆè¦ä»¶"]
        }}
        """
    
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¡ã‚½ãƒƒãƒ‰
    
    def _create_fallback_tasks(self, employee: Employee, analysis: Dict[str, Any]) -> List[SubTask]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®åŸºæœ¬ã‚¿ã‚¹ã‚¯ä½œæˆ"""
        basic_tasks = []
        for i, area in enumerate(employee.improvement_areas[:3]):
            task = SubTask(
                id=f"fallback_task_{employee.id}_{i+1}",
                name=f"{area}ã®æ”¹å–„",
                description=f"{area}ã«é–¢ã™ã‚‹ã‚¹ã‚­ãƒ«å‘ä¸Šã‚¿ã‚¹ã‚¯",
                priority="medium",
                complexity="moderate",
                estimated_duration=120,
                dependencies=[],
                required_skills=[area],
                success_criteria=[f"{area}ã®åŸºæœ¬çš„ãªæ”¹å–„"],
                resources_needed=["å­¦ç¿’æ•™æ", "ç·´ç¿’æ©Ÿä¼š"],
                potential_obstacles=["æ™‚é–“ä¸è¶³", "ç†è§£å›°é›£"],
                mitigation_strategies=["æ®µéšçš„å­¦ç¿’", "ãƒ¡ãƒ³ã‚¿ãƒ¼æ”¯æ´"],
                created_at=datetime.now(),
                due_date=datetime.now() + timedelta(days=7*(i+1))
            )
            basic_tasks.append(task)
        return basic_tasks
    
    def _create_fallback_milestones(self, employee: Employee, tasks: List[SubTask]) -> List[LearningMilestone]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ä½œæˆ"""
        return [
            LearningMilestone(
                id=f"fallback_milestone_{employee.id}_1",
                name="åˆæœŸã‚¹ã‚­ãƒ«ç¿’å¾—",
                description="åŸºæœ¬çš„ãªã‚¹ã‚­ãƒ«ã®ç¿’å¾—",
                target_date=datetime.now() + timedelta(weeks=2),
                success_metrics=["åŸºæœ¬èª²é¡Œã®å®Œäº†"],
                validation_methods=["å®Ÿè·µãƒ†ã‚¹ãƒˆ"],
                reward_system="é”æˆèªè­˜",
                dependencies=[]
            )
        ]
    
    def _create_fallback_adaptive_strategies(self, employee: Employee) -> List[AdaptiveStrategy]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®é©å¿œæˆ¦ç•¥ä½œæˆ"""
        return [
            AdaptiveStrategy(
                strategy_type="learning_pace",
                trigger_conditions=["é€²æ—é…å»¶"],
                adaptations=["ã‚¿ã‚¹ã‚¯åˆ†å‰²", "è¿½åŠ ã‚µãƒãƒ¼ãƒˆ"],
                monitoring_metrics=["å®Œäº†ç‡", "ç†è§£åº¦"],
                escalation_criteria=["3æ—¥é€£ç¶šé…å»¶"]
            )
        ]
    
    def _create_fallback_risk_assessment(self) -> Dict[str, Any]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ãƒªã‚¹ã‚¯è©•ä¾¡ä½œæˆ"""
        return {
            "identified_risks": [
                {
                    "risk_type": "time_management",
                    "description": "æ™‚é–“ç®¡ç†ã®èª²é¡Œ",
                    "probability": "medium",
                    "impact": "medium",
                    "risk_score": "5"
                }
            ],
            "mitigation_strategies": [
                {
                    "risk_type": "time_management",
                    "strategy": "ã‚¿ã‚¹ã‚¯å„ªå…ˆé †ä½ä»˜ã‘",
                    "preventive_actions": ["ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç®¡ç†"],
                    "contingency_plans": ["è¿½åŠ ã‚µãƒãƒ¼ãƒˆæä¾›"]
                }
            ],
            "monitoring_plan": {
                "early_warning_indicators": ["é€²æ—é…å»¶"],
                "monitoring_frequency": "é€±æ¬¡",
                "escalation_procedures": ["ãƒ¡ãƒ³ã‚¿ãƒ¼ä»‹å…¥"]
            },
            "overall_risk_level": "medium"
        }