"""
å‹•çš„çŸ¥è­˜æ¤œç´¢ã‚µãƒ¼ãƒ“ã‚¹
Webæ¤œç´¢ã€æŠ€è¡“æƒ…å ±æ¤œç´¢ã€æ¥­ç•Œãƒˆãƒ¬ãƒ³ãƒ‰æ¤œç´¢ã‚’çµ±åˆ
"""

import json
import asyncio
import logging
import aiohttp
from typing import List, Dict, Any, Optional
from datetime import datetime


def safe_json_dumps(obj, **kwargs):
    """datetimeå¯¾å¿œã®JSONã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¶ãƒ¼"""
    def default_serializer(o):
        if isinstance(o, datetime):
            return o.isoformat()
        raise TypeError(f"Object of type {type(o)} is not JSON serializable")
    
    return json.dumps(obj, default=default_serializer, **kwargs)

from .llm_service import LLMService


class KnowledgeSearchService:
    """
    ãƒ¡ãƒ³ãƒ†ã‚£ã®ãƒ‹ãƒ¼ã‚ºã«å¿œã˜ãŸå‹•çš„ãªçŸ¥è­˜æ¤œç´¢ã‚’å®Ÿè¡Œ
    Webæ¤œç´¢ã€æŠ€è¡“æƒ…å ±ã€æ¥­ç•Œãƒˆãƒ¬ãƒ³ãƒ‰ã‚’è‡ªå¾‹çš„ã«åé›†
    """
    
    def __init__(self):
        self.llm_service = LLMService()
        self.logger = logging.getLogger(__name__)
        self.search_history: List[Dict[str, Any]] = []
        
    async def web_search(self, query: str, max_results: int = 5) -> Dict[str, Any]:
        """Webæ¤œç´¢ã®å®Ÿè¡Œï¼ˆWebSearchãƒ„ãƒ¼ãƒ«ã®æ´»ç”¨ï¼‰"""
        self.logger.info(f"ğŸŒ Webæ¤œç´¢å®Ÿè¡Œ: {query}")
        
        try:
            # WebSearchãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯é©åˆ‡ãªAPIå‘¼ã³å‡ºã—ï¼‰
            search_results = await self._execute_web_search(query, max_results)
            
            # LLMã«ã‚ˆã‚‹æ¤œç´¢çµæœã®è¦ç´„ã¨é–¢é€£æ€§è©•ä¾¡
            analyzed_results = await self._analyze_search_results(query, search_results)
            
            # æ¤œç´¢å±¥æ­´ã«è¨˜éŒ²
            self.search_history.append({
                "timestamp": datetime.now(),
                "query": query,
                "type": "web_search",
                "results_count": len(search_results),
                "relevance_score": analyzed_results.get("average_relevance", 0)
            })
            
            return analyzed_results
            
        except Exception as e:
            self.logger.error(f"Webæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e), "results": []}
    
    async def technical_knowledge_search(self, query: str, domain: str = "general") -> Dict[str, Any]:
        """æŠ€è¡“çŸ¥è­˜ã®å°‚é–€æ¤œç´¢"""
        self.logger.info(f"ğŸ”§ æŠ€è¡“çŸ¥è­˜æ¤œç´¢å®Ÿè¡Œ: {query} (ãƒ‰ãƒ¡ã‚¤ãƒ³: {domain})")
        
        # ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–å‹ã‚¯ã‚¨ãƒªã®ç”Ÿæˆ
        specialized_queries = await self._generate_technical_queries(query, domain)
        
        all_results = []
        for spec_query in specialized_queries:
            # æŠ€è¡“æƒ…å ±æºã§ã®æ¤œç´¢
            results = await self._search_technical_sources(spec_query, domain)
            all_results.extend(results)
        
        # é‡è¤‡é™¤å»ã¨é–¢é€£æ€§ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        ranked_results = await self._rank_and_deduplicate(all_results, query)
        
        # LLMã«ã‚ˆã‚‹æŠ€è¡“æƒ…å ±ã®çµ±åˆã¨æ´å¯ŸæŠ½å‡º
        technical_insights = await self._extract_technical_insights(ranked_results, query, domain)
        
        return {
            "query": query,
            "domain": domain,
            "results": ranked_results,
            "technical_insights": technical_insights,
            "confidence_score": technical_insights.get("confidence", 0.7)
        }
    
    async def industry_trend_search(self, industry: str, focus_area: str = None) -> Dict[str, Any]:
        """æ¥­ç•Œãƒˆãƒ¬ãƒ³ãƒ‰æ¤œç´¢"""
        self.logger.info(f"ğŸ“ˆ æ¥­ç•Œãƒˆãƒ¬ãƒ³ãƒ‰æ¤œç´¢å®Ÿè¡Œ: {industry} (ãƒ•ã‚©ãƒ¼ã‚«ã‚¹: {focus_area})")
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œç´¢ã‚¯ã‚¨ãƒªã®ç”Ÿæˆ
        trend_queries = await self._generate_trend_queries(industry, focus_area)
        
        trend_data = {}
        for query_type, queries in trend_queries.items():
            query_results = []
            for query in queries:
                result = await self._search_trend_sources(query, query_type)
                query_results.append(result)
            trend_data[query_type] = query_results
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã¨ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º
        trend_analysis = await self._analyze_industry_trends(trend_data, industry, focus_area)
        
        return {
            "industry": industry,
            "focus_area": focus_area,
            "trend_data": trend_data,
            "trend_analysis": trend_analysis,
            "last_updated": datetime.now().isoformat()
        }
    
    async def contextual_knowledge_search(self, employee_context: Dict[str, Any], specific_need: str) -> Dict[str, Any]:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè€ƒæ…®å‹çŸ¥è­˜æ¤œç´¢"""
        self.logger.info(f"ğŸ¯ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå‹æ¤œç´¢å®Ÿè¡Œ: {specific_need}")
        
        # ç¤¾å“¡ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ãã‚¯ã‚¨ãƒªç”Ÿæˆ
        contextual_queries = await self._generate_contextual_queries(employee_context, specific_need)
        
        # è¤‡æ•°ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã®æƒ…å ±åé›†
        search_tasks = []
        for query_info in contextual_queries:
            if query_info["type"] == "web":
                task = self.web_search(query_info["query"])
            elif query_info["type"] == "technical":
                task = self.technical_knowledge_search(query_info["query"], query_info.get("domain", "general"))
            elif query_info["type"] == "industry":
                task = self.industry_trend_search(query_info.get("industry"), query_info.get("focus"))
            
            search_tasks.append(task)
        
        # ä¸¦è¡Œæ¤œç´¢å®Ÿè¡Œ
        search_results = await asyncio.gather(*search_tasks, return_exceptions=True)
        
        # çµæœã®çµ±åˆã¨é–¢é€£æ€§è©•ä¾¡
        integrated_results = await self._integrate_contextual_results(
            search_results, employee_context, specific_need
        )
        
        return integrated_results
    
    async def adaptive_resource_discovery(self, learning_goal: str, learner_profile: Dict[str, Any]) -> Dict[str, Any]:
        """å­¦ç¿’è€…ã«é©å¿œã—ãŸãƒªã‚½ãƒ¼ã‚¹ç™ºè¦‹"""
        self.logger.info(f"ğŸ“š é©å¿œçš„ãƒªã‚½ãƒ¼ã‚¹ç™ºè¦‹: {learning_goal}")
        
        # å­¦ç¿’è€…ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã«åŸºã¥ããƒªã‚½ãƒ¼ã‚¹æ¤œç´¢
        resource_queries = await self._generate_resource_queries(learning_goal, learner_profile)
        
        discovered_resources = {}
        for resource_type, queries in resource_queries.items():
            type_results = []
            for query in queries:
                resources = await self._search_learning_resources(query, resource_type, learner_profile)
                type_results.extend(resources)
            
            # ãƒªã‚½ãƒ¼ã‚¹ã®å“è³ªè©•ä¾¡ã¨ãƒ©ãƒ³ã‚­ãƒ³ã‚°
            ranked_resources = await self._evaluate_and_rank_resources(
                type_results, learning_goal, learner_profile
            )
            discovered_resources[resource_type] = ranked_resources
        
        # ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸå­¦ç¿’ãƒ‘ã‚¹ã®ææ¡ˆ
        learning_path = await self._suggest_learning_path(discovered_resources, learning_goal, learner_profile)
        
        return {
            "learning_goal": learning_goal,
            "learner_profile": learner_profile,
            "discovered_resources": discovered_resources,
            "suggested_learning_path": learning_path,
            "personalization_score": learning_path.get("personalization_score", 0.7)
        }
    
    # ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒ¡ã‚½ãƒƒãƒ‰
    
    async def _execute_web_search(self, query: str, max_results: int) -> List[Dict[str, Any]]:
        """å®Ÿéš›ã®Webæ¤œç´¢å®Ÿè¡Œï¼ˆWebSearchãƒ„ãƒ¼ãƒ«çµ±åˆï¼‰"""
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€åˆ©ç”¨å¯èƒ½ãªWebSearchãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã—
        # ã“ã“ã§ã¯ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
        mock_results = [
            {
                "title": f"æ¤œç´¢çµæœ {i+1}: {query}",
                "url": f"https://example.com/result-{i+1}",
                "snippet": f"ã“ã®çµæœã¯{query}ã«é–¢ã™ã‚‹æœ‰ç”¨ãªæƒ…å ±ã‚’å«ã‚“ã§ã„ã¾ã™ã€‚",
                "relevance_score": 0.8 - (i * 0.1)
            }
            for i in range(min(max_results, 3))
        ]
        return mock_results
    
    async def _analyze_search_results(self, query: str, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """LLMã«ã‚ˆã‚‹æ¤œç´¢çµæœã®åˆ†æ"""
        analysis_prompt = f"""
        ä»¥ä¸‹ã®æ¤œç´¢çµæœã‚’åˆ†æã—ã€ã‚¯ã‚¨ãƒªã€Œ{query}ã€ã¨ã®é–¢é€£æ€§ã¨æœ‰ç”¨æ€§ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
        
        æ¤œç´¢çµæœ: {safe_json_dumps(results, ensure_ascii=False, indent=2)}
        
        ä»¥ä¸‹ã®å½¢å¼ã§åˆ†æçµæœã‚’è¿”ã—ã¦ãã ã•ã„ï¼š
        {{
            "summary": "æ¤œç´¢çµæœã®è¦ç´„",
            "key_insights": ["ä¸»è¦ãªæ´å¯Ÿã®ãƒªã‚¹ãƒˆ"],
            "relevance_scores": [å„çµæœã®é–¢é€£æ€§ã‚¹ã‚³ã‚¢ï¼ˆ0-1ï¼‰],
            "average_relevance": å¹³å‡é–¢é€£æ€§ã‚¹ã‚³ã‚¢,
            "recommended_actions": ["æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"],
            "additional_search_suggestions": ["è¿½åŠ æ¤œç´¢ææ¡ˆ"]
        }}
        """
        
        if self.llm_service.is_available():
            try:
                analysis = await self.llm_service.analyze_content(analysis_prompt)
                return json.loads(analysis) if isinstance(analysis, str) else analysis
            except Exception as e:
                self.logger.warning(f"LLMåˆ†æå¤±æ•—: {e}")
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç°¡å˜ãªåˆ†æ
        return {
            "summary": f"ã€Œ{query}ã€ã«é–¢ã™ã‚‹{len(results)}ä»¶ã®æ¤œç´¢çµæœ",
            "key_insights": ["åŸºæœ¬çš„ãªæƒ…å ±ãŒåé›†ã•ã‚Œã¾ã—ãŸ"],
            "relevance_scores": [result.get("relevance_score", 0.5) for result in results],
            "average_relevance": sum(result.get("relevance_score", 0.5) for result in results) / len(results) if results else 0,
            "recommended_actions": ["çµæœã‚’è©³ã—ãç¢ºèªã—ã¦ãã ã•ã„"],
            "additional_search_suggestions": []
        }
    
    async def _generate_technical_queries(self, query: str, domain: str) -> List[str]:
        """æŠ€è¡“ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹åŒ–å‹ã‚¯ã‚¨ãƒªã®ç”Ÿæˆ"""
        generation_prompt = f"""
        ã€Œ{query}ã€ã«ã¤ã„ã¦ã€{domain}ãƒ‰ãƒ¡ã‚¤ãƒ³ã§ã®æŠ€è¡“æ¤œç´¢ã«æœ€é©åŒ–ã•ã‚ŒãŸã‚¯ã‚¨ãƒªã‚’3-5å€‹ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
        
        è¦æ±‚:
        - å°‚é–€ç”¨èªã‚’é©åˆ‡ã«ä½¿ç”¨
        - æ¤œç´¢åŠ¹ç‡ã‚’æœ€å¤§åŒ–
        - å…·ä½“çš„ã§å®Ÿè·µçš„ãªæƒ…å ±ã‚’å–å¾—ã§ãã‚‹å½¢å¼
        
        JSONé…åˆ—å½¢å¼ã§è¿”ã—ã¦ãã ã•ã„: ["ã‚¯ã‚¨ãƒª1", "ã‚¯ã‚¨ãƒª2", ...]
        """
        
        if self.llm_service.is_available():
            try:
                generated = await self.llm_service.generate_queries(generation_prompt)
                return json.loads(generated) if isinstance(generated, str) else generated
            except:
                pass
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        return [
            f"{query} {domain} best practices",
            f"{query} {domain} tutorial guide",
            f"{query} {domain} implementation example"
        ]
    
    async def _search_technical_sources(self, query: str, domain: str) -> List[Dict[str, Any]]:
        """æŠ€è¡“æƒ…å ±æºã§ã®æ¤œç´¢"""
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯æŠ€è¡“æ–‡æ›¸ã€API docsã€GitHubç­‰ã‚’æ¤œç´¢
        return [
            {
                "source": "æŠ€è¡“æ–‡æ›¸",
                "title": f"{domain}: {query}",
                "content": f"{query}ã«é–¢ã™ã‚‹æŠ€è¡“çš„ãªè©³ç´°æƒ…å ±",
                "relevance": 0.85,
                "authority_score": 0.9
            }
        ]
    
    async def _rank_and_deduplicate(self, results: List[Dict[str, Any]], original_query: str) -> List[Dict[str, Any]]:
        """çµæœã®ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã¨é‡è¤‡é™¤å»"""
        # ç°¡å˜ãªé‡è¤‡é™¤å»ã¨ã‚¹ã‚³ã‚¢ãƒ™ãƒ¼ã‚¹ã®ã‚½ãƒ¼ãƒˆ
        unique_results = []
        seen_titles = set()
        
        for result in results:
            title = result.get("title", "")
            if title not in seen_titles:
                seen_titles.add(title)
                unique_results.append(result)
        
        # é–¢é€£æ€§ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
        return sorted(unique_results, key=lambda x: x.get("relevance", 0), reverse=True)
    
    async def _extract_technical_insights(self, results: List[Dict[str, Any]], query: str, domain: str) -> Dict[str, Any]:
        """æŠ€è¡“æƒ…å ±ã‹ã‚‰ã®æ´å¯ŸæŠ½å‡º"""
        if not results:
            return {"insights": [], "confidence": 0.0}
        
        insights_prompt = f"""
        ä»¥ä¸‹ã®æŠ€è¡“æ¤œç´¢çµæœã‹ã‚‰ã€ã€Œ{query}ã€ï¼ˆ{domain}ãƒ‰ãƒ¡ã‚¤ãƒ³ï¼‰ã«é–¢ã™ã‚‹é‡è¦ãªæ´å¯Ÿã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
        
        æ¤œç´¢çµæœ: {safe_json_dumps(results, ensure_ascii=False, indent=2)}
        
        ä»¥ä¸‹ã®å½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ï¼š
        {{
            "insights": ["æ´å¯Ÿ1", "æ´å¯Ÿ2", ...],
            "best_practices": ["ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹1", ...],
            "common_pitfalls": ["ã‚ˆãã‚ã‚‹è½ã¨ã—ç©´1", ...],
            "recommended_tools": ["æ¨å¥¨ãƒ„ãƒ¼ãƒ«1", ...],
            "confidence": ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ï¼ˆ0-1ï¼‰
        }}
        """
        
        if self.llm_service.is_available():
            try:
                insights = await self.llm_service.extract_insights(insights_prompt)
                return json.loads(insights) if isinstance(insights, str) else insights
            except:
                pass
        
        return {
            "insights": [f"{domain}ã§ã®{query}ã«é–¢ã™ã‚‹åŸºæœ¬æƒ…å ±ãŒåé›†ã•ã‚Œã¾ã—ãŸ"],
            "best_practices": [],
            "common_pitfalls": [],
            "recommended_tools": [],
            "confidence": 0.6
        }
    
    async def _generate_trend_queries(self, industry: str, focus_area: str = None) -> Dict[str, List[str]]:
        """æ¥­ç•Œãƒˆãƒ¬ãƒ³ãƒ‰æ¤œç´¢ã‚¯ã‚¨ãƒªã®ç”Ÿæˆ"""
        base_queries = {
            "market_trends": [f"{industry} market trends 2024", f"{industry} industry outlook"],
            "technology_trends": [f"{industry} technology trends", f"emerging tech {industry}"],
            "skill_demands": [f"{industry} skills demand", f"in-demand skills {industry}"]
        }
        
        if focus_area:
            for category in base_queries:
                base_queries[category].append(f"{focus_area} {industry} trends")
        
        return base_queries
    
    async def _search_trend_sources(self, query: str, query_type: str) -> Dict[str, Any]:
        """ãƒˆãƒ¬ãƒ³ãƒ‰ã‚½ãƒ¼ã‚¹ã§ã®æ¤œç´¢"""
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯æ¥­ç•Œãƒ¬ãƒãƒ¼ãƒˆã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã€èª¿æŸ»ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œç´¢
        return {
            "query": query,
            "type": query_type,
            "data": f"{query}ã«é–¢ã™ã‚‹ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿",
            "timestamp": datetime.now().isoformat(),
            "confidence": 0.75
        }
    
    async def _analyze_industry_trends(self, trend_data: Dict[str, Any], industry: str, focus_area: str) -> Dict[str, Any]:
        """æ¥­ç•Œãƒˆãƒ¬ãƒ³ãƒ‰ã®åˆ†æ"""
        analysis_prompt = f"""
        {industry}æ¥­ç•Œã®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚
        ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã‚¨ãƒªã‚¢: {focus_area}
        
        ãƒ‡ãƒ¼ã‚¿: {safe_json_dumps(trend_data, ensure_ascii=False, indent=2)}
        
        ä»¥ä¸‹ã®å½¢å¼ã§åˆ†æçµæœã‚’è¿”ã—ã¦ãã ã•ã„ï¼š
        {{
            "key_trends": ["ä¸»è¦ãƒˆãƒ¬ãƒ³ãƒ‰1", "ä¸»è¦ãƒˆãƒ¬ãƒ³ãƒ‰2", ...],
            "emerging_opportunities": ["æ–°èˆˆæ©Ÿä¼š1", ...],
            "skill_requirements": ["å¿…è¦ã‚¹ã‚­ãƒ«1", ...],
            "future_outlook": "å°†æ¥å±•æœ›",
            "implications_for_learning": "å­¦ç¿’ã¸ã®ç¤ºå”†"
        }}
        """
        
        if self.llm_service.is_available():
            try:
                analysis = await self.llm_service.analyze_trends(analysis_prompt)
                return json.loads(analysis) if isinstance(analysis, str) else analysis
            except:
                pass
        
        return {
            "key_trends": [f"{industry}æ¥­ç•Œã®åŸºæœ¬çš„ãªãƒˆãƒ¬ãƒ³ãƒ‰"],
            "emerging_opportunities": [],
            "skill_requirements": [],
            "future_outlook": "ç¶™ç¶šçš„ãªæˆé•·ãŒæœŸå¾…ã•ã‚Œã¾ã™",
            "implications_for_learning": "åŸºæœ¬ã‚¹ã‚­ãƒ«ã®ç¿’å¾—ãŒé‡è¦ã§ã™"
        }
    
    # è¿½åŠ ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯å®Ÿè£…ã‚’ç¶™ç¶š...
    
    async def _generate_contextual_queries(self, employee_context: Dict[str, Any], specific_need: str) -> List[Dict[str, str]]:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªç”Ÿæˆ"""
        return [
            {"type": "web", "query": f"{specific_need} for {employee_context.get('department', 'general')}"},
            {"type": "technical", "query": specific_need, "domain": employee_context.get('department', 'general')}
        ]
    
    async def _integrate_contextual_results(self, results: List[Any], context: Dict[str, Any], need: str) -> Dict[str, Any]:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆçµæœã®çµ±åˆ"""
        valid_results = [r for r in results if not isinstance(r, Exception)]
        return {
            "integrated_results": valid_results,
            "context_relevance": 0.8,
            "recommendation": f"{need}ã«é–¢ã™ã‚‹æƒ…å ±ãŒåé›†ã•ã‚Œã¾ã—ãŸ"
        }
    
    async def _generate_resource_queries(self, goal: str, profile: Dict[str, Any]) -> Dict[str, List[str]]:
        """ãƒªã‚½ãƒ¼ã‚¹æ¤œç´¢ã‚¯ã‚¨ãƒªç”Ÿæˆ"""
        return {
            "courses": [f"{goal} online course", f"{goal} training"],
            "books": [f"{goal} book recommendation", f"best books {goal}"],
            "tools": [f"{goal} tools", f"{goal} software"]
        }
    
    async def _search_learning_resources(self, query: str, resource_type: str, profile: Dict[str, Any]) -> List[Dict[str, Any]]:
        """å­¦ç¿’ãƒªã‚½ãƒ¼ã‚¹æ¤œç´¢"""
        return [
            {
                "title": f"{resource_type}: {query}",
                "type": resource_type,
                "quality_score": 0.8,
                "difficulty_level": profile.get("skill_level", "beginner")
            }
        ]
    
    async def _evaluate_and_rank_resources(self, resources: List[Dict[str, Any]], goal: str, profile: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ãƒªã‚½ãƒ¼ã‚¹è©•ä¾¡ã¨ãƒ©ãƒ³ã‚­ãƒ³ã‚°"""
        return sorted(resources, key=lambda x: x.get("quality_score", 0), reverse=True)
    
    async def _suggest_learning_path(self, resources: Dict[str, Any], goal: str, profile: Dict[str, Any]) -> Dict[str, Any]:
        """å­¦ç¿’ãƒ‘ã‚¹ææ¡ˆ"""
        return {
            "path_steps": ["ã‚¹ãƒ†ãƒƒãƒ—1: åŸºç¤å­¦ç¿’", "ã‚¹ãƒ†ãƒƒãƒ—2: å®Ÿè·µæ¼”ç¿’"],
            "estimated_duration": "30æ—¥",
            "personalization_score": 0.85
        }